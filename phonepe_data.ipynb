{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pakages\n",
    "import os\n",
    "import psycopg2\n",
    "import json\n",
    "import git\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_insurance\n",
    "path1= \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "\n",
    "agg_insur_list= os.listdir(path1)\n",
    "\n",
    "columns1= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Insurance_type\":[], \"Insurance_count\":[],\"Insurance_amount\":[] }\n",
    "\n",
    "for state in agg_insur_list:\n",
    "    cur_states =path1+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            A = json.load(data)\n",
    "\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns1[\"Insurance_type\"].append(name)\n",
    "                columns1[\"Insurance_count\"].append(count)\n",
    "                columns1[\"Insurance_amount\"].append(amount)\n",
    "                columns1[\"States\"].append(state)\n",
    "                columns1[\"Years\"].append(year)\n",
    "                columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "\n",
    "aggre_insurance = pd.DataFrame(columns1)\n",
    "\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.title()\n",
    "aggre_insurance['States'] = aggre_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_transaction\n",
    "path2 = \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "         \n",
    "agg_tran_list = os.listdir(path2)\n",
    "\n",
    "columns2 ={\"States\":[], \"Years\":[], \"Quarter\":[], \"Transaction_type\":[], \"Transaction_count\":[],\"Transaction_amount\":[] }\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states =path2+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            B = json.load(data)\n",
    "\n",
    "            for i in B[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns2[\"Transaction_type\"].append(name)\n",
    "                columns2[\"Transaction_count\"].append(count)\n",
    "                columns2[\"Transaction_amount\"].append(amount)\n",
    "                columns2[\"States\"].append(state)\n",
    "                columns2[\"Years\"].append(year)\n",
    "                columns2[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_transaction = pd.DataFrame(columns2)\n",
    "\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.title()\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_user\n",
    "path3 = \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/aggregated/user/country/india/state/\"\n",
    "         \n",
    "agg_user_list = os.listdir(path3)\n",
    "\n",
    "columns3 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Brands\":[],\"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cur_states = path3+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            C = json.load(data)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for i in C[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"Transaction_count\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"States\"].append(state)\n",
    "                    columns3[\"Years\"].append(year)\n",
    "                    columns3[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggre_user = pd.DataFrame(columns3)\n",
    "\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.title()\n",
    "aggre_user['States'] = aggre_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance\n",
    "path4= \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "map_insur_list= os.listdir(path4)\n",
    "\n",
    "columns4= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"Transaction_count\":[],\"Transaction_amount\":[] }\n",
    "\n",
    "for state in map_insur_list:\n",
    "    cur_states =path4+state+\"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        agg_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            D = json.load(data)\n",
    "\n",
    "            for i in D[\"data\"][\"hoverDataList\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"metric\"][0][\"count\"]\n",
    "                amount = i[\"metric\"][0][\"amount\"]\n",
    "                columns4[\"Districts\"].append(name)\n",
    "                columns4[\"Transaction_count\"].append(count)\n",
    "                columns4[\"Transaction_amount\"].append(amount)\n",
    "                columns4[\"States\"].append(state)\n",
    "                columns4[\"Years\"].append(year)\n",
    "                columns4[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "\n",
    "map_insurance = pd.DataFrame(columns4)\n",
    "\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.title()\n",
    "map_insurance['States'] = map_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction\n",
    "path5= \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_tran_list = os.listdir(path5)\n",
    "\n",
    "columns5 = {\"States\":[], \"Years\":[], \"Quarter\":[],\"District\":[], \"Transaction_count\":[],\"Transaction_amount\":[]}\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = path5+state+\"/\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in map_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        map_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in map_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            E = json.load(data)\n",
    "\n",
    "            for i in E['data'][\"hoverDataList\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"metric\"][0][\"count\"]\n",
    "                amount = i[\"metric\"][0][\"amount\"]\n",
    "                columns5[\"District\"].append(name)\n",
    "                columns5[\"Transaction_count\"].append(count)\n",
    "                columns5[\"Transaction_amount\"].append(amount)\n",
    "                columns5[\"States\"].append(state)\n",
    "                columns5[\"Years\"].append(year)\n",
    "                columns5[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_transaction = pd.DataFrame(columns5)\n",
    "\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.title()\n",
    "map_transaction['States'] = map_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user\n",
    "path6 = \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list = os.listdir(path6)\n",
    "\n",
    "columns6 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"RegisteredUser\":[], \"AppOpens\":[]}\n",
    "\n",
    "for state in map_user_list:\n",
    "    cur_states = path6+state+\"/\"\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in map_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        map_file_list = os.listdir(cur_years)\n",
    "        \n",
    "        for file in map_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            F = json.load(data)\n",
    "\n",
    "            for i in F[\"data\"][\"hoverData\"].items():\n",
    "                district = i[0]\n",
    "                registereduser = i[1][\"registeredUsers\"]\n",
    "                appopens = i[1][\"appOpens\"]\n",
    "                columns6[\"Districts\"].append(district)\n",
    "                columns6[\"RegisteredUser\"].append(registereduser)\n",
    "                columns6[\"AppOpens\"].append(appopens)\n",
    "                columns6[\"States\"].append(state)\n",
    "                columns6[\"Years\"].append(year)\n",
    "                columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_user = pd.DataFrame(columns6)\n",
    "\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user['States'] = map_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_insurance\n",
    "\n",
    "path7 = \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/top/insurance/country/india/state/\"\n",
    "\n",
    "top_insur_list = os.listdir(path7)\n",
    "\n",
    "columns7 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_insur_list:\n",
    "    cur_states = path7+state+\"/\"\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        top_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            G = json.load(data)\n",
    "\n",
    "            for i in G[\"data\"][\"pincodes\"]:\n",
    "                entityName = i[\"entityName\"]\n",
    "                count = i[\"metric\"][\"count\"]\n",
    "                amount = i[\"metric\"][\"amount\"]\n",
    "                columns7[\"Pincodes\"].append(entityName)\n",
    "                columns7[\"Transaction_count\"].append(count)\n",
    "                columns7[\"Transaction_amount\"].append(amount)\n",
    "                columns7[\"States\"].append(state)\n",
    "                columns7[\"Years\"].append(year)\n",
    "                columns7[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_insur = pd.DataFrame(columns7)\n",
    "\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insur[\"States\"] = top_insur[\"States\"].str.title()\n",
    "top_insur['States'] = top_insur['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top transaction\n",
    "\n",
    "\n",
    "path8=\"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/top/transaction/country/india/state\"\n",
    "\n",
    "top_transaction_list = os.listdir(path8)\n",
    "\n",
    "columns8 = {\n",
    "    \"pincodes\": [],\n",
    "    \"Transaction_count\": [],\n",
    "    \"Transaction_amount\": [],\n",
    "    \"states\": [],\n",
    "    \"years\": [],\n",
    "    \"Quarter\": []\n",
    "}\n",
    "\n",
    "for state in top_transaction_list:\n",
    "    cur_state_path = os.path.join(path8, state)\n",
    "    state_subdirs = os.listdir(cur_state_path)\n",
    "    \n",
    "    for year in state_subdirs:\n",
    "        cur_year = os.path.join(cur_state_path, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file) as f:\n",
    "                data = json.load(f)\n",
    "                for item in data.get(\"data\", {}).get(\"pincodes\", []):\n",
    "                    entityName = item[\"entityName\"]\n",
    "                    count = item[\"metric\"][\"count\"]\n",
    "                    amount = item[\"metric\"][\"amount\"]\n",
    "                    columns8[\"pincodes\"].append(entityName)\n",
    "                    columns8[\"Transaction_count\"].append(count)\n",
    "                    columns8[\"Transaction_amount\"].append(amount)\n",
    "                    columns8[\"states\"].append(state)\n",
    "                    columns8[\"years\"].append(year)\n",
    "                    columns8[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "                    top_transaction = pd.DataFrame(columns8)\n",
    "                    \n",
    "                    \n",
    "top_transaction[\"states\"]=   top_transaction[\"states\"].str.replace('andaman-&-nicobar-islands',\"Andaman & Nicobar\") \n",
    "top_transaction[\"states\"]=   top_transaction[\"states\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"states\"]=    top_transaction[\"states\"].str.title()\n",
    "top_transaction[\"states\"]=   top_transaction[\"states\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra  and Nagar and Haveli and Daman and Diu')            \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user\n",
    "path9 = \"C:/Users/karan/OneDrive/Pictures/Desktop/PHONEPE/pulse/data/top/user/country/india/state/\"\n",
    "top_user_list = os.listdir(path9)\n",
    "\n",
    "columns9 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"RegisteredUser\":[]}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states = path9+state+\"/\"\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_years = cur_states+year+\"/\"\n",
    "        top_file_list = os.listdir(cur_years)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_files = cur_years+file\n",
    "            data = open(cur_files,\"r\")\n",
    "            I = json.load(data)\n",
    "\n",
    "            for i in I[\"data\"][\"pincodes\"]:\n",
    "                name = i[\"name\"]\n",
    "                registeredusers = i[\"registeredUsers\"]\n",
    "                columns9[\"Pincodes\"].append(name)\n",
    "                columns9[\"RegisteredUser\"].append(registereduser)\n",
    "                columns9[\"States\"].append(state)\n",
    "                columns9[\"Years\"].append(year)\n",
    "                columns9[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_user = pd.DataFrame(columns9)\n",
    "\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.title()\n",
    "top_user['States'] = top_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n",
      "Missing columns in dataframe: ['VARCHAR']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming the dataframes are already created: aggre_insurance, aggre_transaction, aggre_user, map_insurance, map_transaction, map_user, top_insur, top_transaction, top_user\n",
    "\n",
    "# PostgreSQL connection\n",
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "                        user=\"postgres\",\n",
    "                        password=\"karan1122\",\n",
    "                        database=\"phonepe_data\",\n",
    "                        port=\"5432\")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "# Function to create tables and insert data\n",
    "def create_and_insert_table(create_query, insert_query, dataframe):\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "    \n",
    "    # Check if the required columns exist in the dataframe\n",
    "    required_columns = [col.split()[-1] for col in create_query.split('(')[1].split(')')[0].split(',')]\n",
    "    missing_columns = [col for col in required_columns if col not in dataframe.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Missing columns in dataframe: {missing_columns}\")\n",
    "        return\n",
    "    \n",
    "    # Insert data in bulk\n",
    "    values = [tuple(row[col] for col in required_columns) for index, row in dataframe.iterrows()]\n",
    "    cursor.executemany(insert_query, values)\n",
    "    mydb.commit()\n",
    "\n",
    "# Aggregated insurance table\n",
    "create_query1 = '''CREATE TABLE IF NOT EXISTS aggregated_insurance (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Insurance_type VARCHAR(50),\n",
    "                      Insurance_count BIGINT,\n",
    "                      Insurance_amount BIGINT)'''\n",
    "insert_query1 = '''INSERT INTO aggregated_insurance (\n",
    "                      States, Years, Quarter, Insurance_type, Insurance_count, Insurance_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query1, insert_query1, aggre_insurance)\n",
    "#aggregated insurance table\n",
    "create_query1= '''CREATE TABLE if not exists aggregated_insurance (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Insurance_type varchar(50),\n",
    "                                                                      Insurance_count bigint,\n",
    "                                                                      Insurance_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query1)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_insurance.iterrows():\n",
    "    insert_query1 = '''INSERT INTO aggregated_insurance (States, Years, Quarter, Insurance_type, Insurance_count, Insurance_amount)\n",
    "                                                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Insurance_type\"],\n",
    "              row[\"Insurance_count\"],\n",
    "              row[\"Insurance_amount\"]\n",
    "              )\n",
    "    cursor.execute(insert_query1,values)\n",
    "    mydb.commit()\n",
    "\n",
    "# Aggregated transaction table\n",
    "create_query2= '''CREATE TABLE IF NOT EXISTS aggregated_transaction (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Transaction_type VARCHAR(50),\n",
    "                      Transaction_count BIGINT,\n",
    "                      Transaction_amount BIGINT)'''\n",
    "insert_query2 = '''INSERT INTO aggregated_transaction (\n",
    "                      States, Years, Quarter, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query2, insert_query2, aggre_transaction)\n",
    "\n",
    "# Aggregated user table\n",
    "create_query3 = '''CREATE TABLE IF NOT EXISTS aggregated_user (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Brands VARCHAR(50),\n",
    "                      Transaction_count BIGINT,\n",
    "                      Percentage FLOAT)'''\n",
    "insert_query3 = '''INSERT INTO aggregated_user (\n",
    "                      States, Years, Quarter, Brands, Transaction_count, Percentage)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query3, insert_query3, aggre_user)\n",
    "\n",
    "# Map insurance table\n",
    "create_query4 = '''CREATE TABLE IF NOT EXISTS map_insurance (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      District VARCHAR(50),\n",
    "                      Transaction_count BIGINT,\n",
    "                      Transaction_amount FLOAT)'''\n",
    "insert_query4= '''INSERT INTO map_insurance (\n",
    "                      States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query4, insert_query4, map_insurance)\n",
    "\n",
    "# Map transaction table\n",
    "create_query5 = '''CREATE TABLE IF NOT EXISTS map_transaction (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      District VARCHAR(50),\n",
    "                      Transaction_count BIGINT,\n",
    "                      Transaction_amount FLOAT)'''\n",
    "insert_query5 = '''INSERT INTO map_transaction (\n",
    "                      States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query5, insert_query5, map_transaction)\n",
    "\n",
    "# Map user table\n",
    "create_query6 = '''CREATE TABLE IF NOT EXISTS map_user (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Districts VARCHAR(50),\n",
    "                      RegisteredUser BIGINT,\n",
    "                      AppOpens BIGINT)'''\n",
    "insert_query6 = '''INSERT INTO map_user (\n",
    "                      States, Years, Quarter, Districts, RegisteredUser, AppOpens)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query6, insert_query6, map_user)\n",
    "\n",
    "# Top insurance table\n",
    "create_query7 = '''CREATE TABLE IF NOT EXISTS top_insurance (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Pincodes INT,\n",
    "                      Transaction_count BIGINT,\n",
    "                      Transaction_amount BIGINT)'''\n",
    "insert_query7 = '''INSERT INTO top_insurance (\n",
    "                      States, Years, Quarter, Pincodes, Transaction_count, Transaction_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query7, insert_query7, top_insur)\n",
    "\n",
    "# Top transaction table\n",
    "create_query8 = '''CREATE TABLE IF NOT EXISTS top_transaction (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Pincodes INT,\n",
    "                      Transaction_count BIGINT,\n",
    "                      Transaction_amount BIGINT)'''\n",
    "insert_query8 = '''INSERT INTO top_transaction (\n",
    "                      States, Years, Quarter, Pincodes, Transaction_count, Transaction_amount)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query8, insert_query8, top_transaction)\n",
    "\n",
    "# Top user table\n",
    "create_query9 = '''CREATE TABLE IF NOT EXISTS top_user (\n",
    "                      States VARCHAR(50),\n",
    "                      Years INT,\n",
    "                      Quarter INT,\n",
    "                      Pincodes INT,\n",
    "                      RegisteredUser BIGINT)'''\n",
    "insert_query9 = '''INSERT INTO top_user (\n",
    "                      States, Years, Quarter, Pincodes, RegisteredUser)\n",
    "                  VALUES (%s, %s, %s, %s, %s)'''\n",
    "create_and_insert_table(create_query9, insert_query9, top_user)\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "mydb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
